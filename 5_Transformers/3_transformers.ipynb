{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_steps = 1000\n",
    "lr = 1e-3\n",
    "context_length = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8' ) as f:\n",
    "    data = f.read().lower()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<UNK>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "chars.remove('3')\n",
    "chars.append('<UNK>')\n",
    "print(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " ';': 10,\n",
       " '?': 11,\n",
       " 'a': 12,\n",
       " 'b': 13,\n",
       " 'c': 14,\n",
       " 'd': 15,\n",
       " 'e': 16,\n",
       " 'f': 17,\n",
       " 'g': 18,\n",
       " 'h': 19,\n",
       " 'i': 20,\n",
       " 'j': 21,\n",
       " 'k': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'q': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'x': 35,\n",
       " 'y': 36,\n",
       " 'z': 37,\n",
       " '<UNK>': 38}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for t in range(len(chars)):\n",
    "    vocab[t] = chars[t]\n",
    "\n",
    "rev_vocab = {v:k for k,v in vocab.items()}\n",
    "rev_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 16, 23, 23, 26, 38]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(text):\n",
    "    out = []\n",
    "    for t in text:\n",
    "        out.append(rev_vocab.get(t, 38)) # 38 is the <UNK>\n",
    "    return out\n",
    "\n",
    "\n",
    "encode('hello1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello<UNK>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode(nums):\n",
    "    out = ''\n",
    "    for i in nums:\n",
    "        out += vocab.get(i, '<UNK>')\n",
    "    return out\n",
    "\n",
    "\n",
    "decode([19, 16, 23, 23, 26, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = encode(data)\n",
    "train_data = encoded_data[:int(0.9*len(encoded_data))]\n",
    "test_data = encoded_data[int(0.9*len(encoded_data)):]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([748845, 457334, 726204, 424344, 734603, 103634, 545085,  62470, 328412,\n",
      "         48875, 942474, 108661,  10514, 394508, 247688, 140337])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, 24, 12, 25, 22, 20, 25, 15,  1, 34, 20, 31, 14, 19,  2,  1, 19, 16,\n",
       "         25, 14, 16,  1, 34, 20, 31, 19,  1, 19, 16, 29,  6,  1],\n",
       "        [ 1, 15, 20, 16,  6,  0, 31, 29, 12, 25, 30, 27, 12, 29, 16, 25, 31,  1,\n",
       "         19, 16, 29, 16, 31, 20, 14, 30,  6,  1, 13, 16,  1, 13],\n",
       "        [25, 18,  1, 31, 26,  1, 31, 19, 16, 24,  1, 13, 26, 31, 19,  9,  1, 34,\n",
       "         16, 29, 16,  1, 24, 36,  1, 34, 20, 17, 16,  5, 30,  1],\n",
       "        [22,  9,  0, 34, 16, 23, 14, 26, 24, 16,  6,  1, 24, 36,  1, 30, 26, 25,\n",
       "          9,  1, 34, 19, 26,  1, 12, 29, 16,  1, 31, 19, 16,  1],\n",
       "        [ 1, 30, 31, 20, 29, 30,  1, 12, 24, 26, 25, 18, 30, 31,  1, 36, 26, 32,\n",
       "         11,  1, 14, 26, 24, 16,  6,  1, 30, 20, 29,  6,  1, 25],\n",
       "        [31, 26,  1, 19, 16, 12, 29,  1, 26, 17,  1, 31, 19, 16, 20, 29,  1, 29,\n",
       "         16, 12, 15, 20, 25, 16, 30, 30,  6,  1, 12, 25, 15,  1],\n",
       "        [21, 32, 23, 20, 16, 31,  9,  0, 18, 20, 33, 16,  1, 24, 16,  6,  1, 18,\n",
       "         20, 33, 16,  1, 24, 16,  2,  1, 26,  6,  1, 31, 16, 23],\n",
       "        [ 1, 30, 12, 36, 30,  1, 19, 16,  9,  1,  5, 12, 18, 16, 15,  1, 14, 32,\n",
       "         30, 31, 26, 24,  6,  0, 13, 32, 31,  1, 13, 36,  1, 36],\n",
       "        [29,  6,  0, 31, 19, 12, 31,  1, 20, 31,  1, 24, 12, 36,  1, 16, 25, 31,\n",
       "         16, 29,  1, 13, 32, 31, 14, 19, 16, 29,  1, 24, 26, 34],\n",
       "        [26, 17, 17, 20, 14, 16, 29,  9,  0, 25, 26,  1, 24, 26, 29, 16,  1, 26,\n",
       "         17,  1, 19, 20, 24, 10,  1, 19, 16,  1, 20, 30,  1, 12],\n",
       "        [ 1, 26, 23, 15,  1, 12, 25, 15,  1, 17, 12, 20, 31, 19, 17, 32, 23,  1,\n",
       "         17, 29, 20, 16, 25, 15,  6,  1, 34, 16,  1, 12, 29, 16],\n",
       "        [16,  1,  5, 33, 26, 20, 15, 16, 15,  1, 31, 19, 16, 16,  6,  1, 13, 32,\n",
       "         31,  1, 20, 25,  1, 24, 16, 29, 16,  1, 30, 27, 20, 31],\n",
       "        [32, 30,  1, 12, 32, 17, 20, 15, 20, 32, 30,  6,  1, 31, 19, 12, 31,  1,\n",
       "         34, 20, 23, 23,  1, 27, 32, 31,  1, 36, 26, 32,  1, 31],\n",
       "        [23, 23,  1, 13, 16,  1, 14, 26, 25, 31, 16, 25, 31, 16, 15,  9,  1, 24,\n",
       "         32, 30, 31,  1, 19, 16,  1, 23, 26, 30, 16,  0, 31, 19],\n",
       "        [16, 15, 34, 12, 29, 15,  6,  1, 25, 26, 13, 23, 16,  1, 36, 26, 29, 22,\n",
       "          0, 24, 36,  1, 27, 29, 20, 25, 14, 16, 23, 36,  1, 17],\n",
       "        [26, 17,  1, 12,  1, 34, 26, 24, 12, 25,  5, 30,  1, 31, 16, 25, 15, 16,\n",
       "         29, 25, 16, 30, 30,  1, 31, 26,  1, 13, 16,  6,  0, 29]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(split='train'):\n",
    "    start = torch.randint(0,len(encoded_data)-context_length-1,(batch_size,))\n",
    "    print(start)\n",
    "    outx, outy = [], []\n",
    "    for i in start:\n",
    "        outx.append(encoded_data[i:i+context_length])\n",
    "        if split == 'train':\n",
    "            outy.append(encoded_data[i+context_length])\n",
    "    if split == 'train': return torch.tensor(outx), torch.tensor(outy)\n",
    "    return torch.tensor(outx)\n",
    "\n",
    "get_batch('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
