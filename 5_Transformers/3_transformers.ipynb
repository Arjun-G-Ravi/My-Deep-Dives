{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_steps = 1000\n",
    "lr = 1e-3\n",
    "context_length = 32\n",
    "embedding_size = 32 # change this in future and test if it works \n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8' ) as f:\n",
    "    data = f.read().lower()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<UNK>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "chars.remove('3')\n",
    "chars.append('<UNK>')\n",
    "print(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " ';': 10,\n",
       " '?': 11,\n",
       " 'a': 12,\n",
       " 'b': 13,\n",
       " 'c': 14,\n",
       " 'd': 15,\n",
       " 'e': 16,\n",
       " 'f': 17,\n",
       " 'g': 18,\n",
       " 'h': 19,\n",
       " 'i': 20,\n",
       " 'j': 21,\n",
       " 'k': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'q': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'x': 35,\n",
       " 'y': 36,\n",
       " 'z': 37,\n",
       " '<UNK>': 38}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for t in range(len(chars)):\n",
    "    vocab[t] = chars[t]\n",
    "\n",
    "rev_vocab = {v:k for k,v in vocab.items()}\n",
    "rev_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 16, 23, 23, 26, 38]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(text):\n",
    "    out = []\n",
    "    for t in text:\n",
    "        out.append(rev_vocab.get(t, 38)) # 38 is the <UNK>\n",
    "    return out\n",
    "\n",
    "\n",
    "encode('hello1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w-tr!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode(nums):\n",
    "    out = ''\n",
    "    for i in nums:\n",
    "        out += vocab.get(i, '<UNK>')\n",
    "    return out\n",
    "\n",
    "\n",
    "decode([34,  7, 31, 29, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = torch.tensor(encode(data), dtype=torch.long)\n",
    "train_data = encoded_data[:int(0.9*len(encoded_data))]\n",
    "test_data = encoded_data[int(0.9*len(encoded_data)):]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(split='train'):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    start = torch.randint(0,len(data)-context_length-1,(batch_size,))\n",
    "    outx = torch.stack([data[i:i+context_length] for i in start]).to(device)\n",
    "    if split == 'test': return outx\n",
    "    outy = torch.stack([data[i+1:i+context_length+1] for i in start]).to(device)\n",
    "    if split == 'train': return outx, outy\n",
    "\n",
    "get_batch('train')[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-6.0916e-01,  1.5004e-02,  3.7631e-02,  ..., -4.4515e-01,\n",
       "          -1.2958e-01, -6.5326e-02],\n",
       "         [-5.0434e-01, -7.0856e-04, -1.3698e-01,  ..., -3.6357e-01,\n",
       "          -1.0415e-01, -8.9459e-02],\n",
       "         [-3.8976e-01, -7.3190e-02, -3.9952e-02,  ..., -3.5339e-01,\n",
       "          -1.0293e-01, -6.0476e-02],\n",
       "         ...,\n",
       "         [-3.8749e-01, -8.6466e-02,  2.9432e-02,  ..., -3.2784e-01,\n",
       "          -1.1670e-01,  8.9313e-02],\n",
       "         [-3.8047e-01, -8.9410e-02,  3.0156e-02,  ..., -3.3121e-01,\n",
       "          -1.2248e-01,  8.6099e-02],\n",
       "         [-3.8272e-01, -9.7038e-02,  2.3258e-02,  ..., -3.2776e-01,\n",
       "          -1.1160e-01,  8.2213e-02]],\n",
       "\n",
       "        [[-3.3604e-01,  7.7048e-03,  1.2669e-01,  ..., -2.4513e-01,\n",
       "          -1.5715e-02,  2.1925e-01],\n",
       "         [-3.0163e-01, -7.1671e-02,  9.0318e-02,  ..., -2.7427e-01,\n",
       "           1.2674e-02,  1.9670e-01],\n",
       "         [-2.7150e-01, -2.2134e-02,  1.2078e-01,  ..., -2.4565e-01,\n",
       "          -2.4494e-02,  1.6907e-01],\n",
       "         ...,\n",
       "         [-4.2085e-01, -4.5457e-02,  1.7969e-02,  ..., -3.0267e-01,\n",
       "          -1.0999e-01,  7.0236e-02],\n",
       "         [-4.1389e-01, -4.2795e-02,  1.0159e-02,  ..., -3.0029e-01,\n",
       "          -1.0040e-01,  6.8390e-02],\n",
       "         [-4.0865e-01, -4.4122e-02,  1.4522e-02,  ..., -3.0521e-01,\n",
       "          -1.0152e-01,  6.9421e-02]],\n",
       "\n",
       "        [[-2.0265e-01, -2.3069e-02,  1.9347e-01,  ..., -2.9149e-01,\n",
       "          -3.6481e-02,  6.9965e-02],\n",
       "         [-3.1981e-01, -2.6930e-02, -3.8500e-02,  ..., -3.9645e-01,\n",
       "          -1.0800e-01,  7.4780e-03],\n",
       "         [-3.9777e-01, -3.9183e-02,  1.3485e-02,  ..., -4.6806e-01,\n",
       "          -2.1913e-01,  2.7832e-02],\n",
       "         ...,\n",
       "         [-3.8579e-01, -8.6494e-03,  1.0933e-02,  ..., -3.8122e-01,\n",
       "          -8.4935e-02,  7.0493e-02],\n",
       "         [-3.8789e-01, -2.0259e-03,  8.4979e-03,  ..., -3.7746e-01,\n",
       "          -7.4929e-02,  6.0790e-02],\n",
       "         [-3.8912e-01, -7.7817e-03,  4.3096e-03,  ..., -3.7481e-01,\n",
       "          -8.3528e-02,  6.5419e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-4.5424e-01, -2.0196e-01, -1.0249e-01,  ..., -5.6010e-01,\n",
       "          -2.6005e-01,  1.0783e-01],\n",
       "         [-5.3881e-01, -2.2499e-01, -1.2839e-01,  ..., -3.9936e-01,\n",
       "          -8.7490e-02,  5.4743e-02],\n",
       "         [-4.0835e-01, -2.6951e-01, -5.1370e-02,  ..., -2.5427e-01,\n",
       "          -5.5002e-02,  6.8360e-02],\n",
       "         ...,\n",
       "         [-4.4675e-01, -4.3590e-02, -1.7183e-02,  ..., -3.5301e-01,\n",
       "          -1.3550e-01,  5.0230e-02],\n",
       "         [-4.4265e-01, -4.4633e-02, -2.0134e-02,  ..., -3.4953e-01,\n",
       "          -1.2328e-01,  4.6221e-02],\n",
       "         [-4.3970e-01, -3.7540e-02, -1.7739e-02,  ..., -3.3964e-01,\n",
       "          -1.2519e-01,  4.9201e-02]],\n",
       "\n",
       "        [[-7.9422e-02, -2.9069e-01, -2.5148e-02,  ..., -2.4331e-01,\n",
       "           2.2648e-01, -1.7868e-01],\n",
       "         [-2.2676e-01, -2.1506e-01, -8.3677e-02,  ..., -3.1301e-01,\n",
       "           1.2561e-01, -9.5192e-02],\n",
       "         [-3.0777e-01, -1.4485e-01, -7.3336e-02,  ..., -4.3186e-01,\n",
       "          -3.2535e-02, -1.3465e-01],\n",
       "         ...,\n",
       "         [-3.8650e-01, -1.8269e-02, -7.0366e-02,  ..., -3.4961e-01,\n",
       "          -1.1342e-01,  3.3420e-02],\n",
       "         [-3.8609e-01, -1.5414e-02, -6.0435e-02,  ..., -3.5073e-01,\n",
       "          -1.1996e-01,  3.6825e-02],\n",
       "         [-3.8758e-01, -2.1349e-02, -6.3720e-02,  ..., -3.5051e-01,\n",
       "          -1.2038e-01,  3.6125e-02]],\n",
       "\n",
       "        [[-5.6384e-01,  2.2867e-02, -4.2131e-04,  ..., -3.4694e-01,\n",
       "          -1.5701e-01,  2.6203e-01],\n",
       "         [-5.2950e-01, -1.2033e-01, -1.3849e-01,  ..., -3.5244e-01,\n",
       "          -3.7746e-02,  1.6309e-01],\n",
       "         [-3.7860e-01,  6.4706e-03, -8.4169e-02,  ..., -3.0853e-01,\n",
       "          -1.2458e-01,  6.8379e-02],\n",
       "         ...,\n",
       "         [-4.7704e-01, -2.6027e-02, -5.5057e-02,  ..., -2.7201e-01,\n",
       "          -8.9656e-02,  1.1983e-01],\n",
       "         [-4.8203e-01, -2.3884e-02, -5.9188e-02,  ..., -2.7198e-01,\n",
       "          -9.0606e-02,  1.2233e-01],\n",
       "         [-4.7902e-01, -2.3219e-02, -5.1830e-02,  ..., -2.8020e-01,\n",
       "          -8.7929e-02,  1.1944e-01]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.Q = nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.K = nn.Linear(embedding_size, head_size, bias=False)\n",
    "        self.V = nn.Linear(embedding_size, head_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape # BatchSize Time ContextSize\n",
    "        k = self.K(x)\n",
    "        q = self.Q(x)\n",
    "        v = self.V(x)\n",
    "\n",
    "        out = q@k.transpose(-2,-1)\n",
    "        out = out*embedding_size**-0.5\n",
    "        \n",
    "        out = out*torch.tril(torch.ones(32,32)) # probably can be improved. No need for element wise mul here\n",
    "        out = out.masked_fill(out==0, float('-inf'))# masking\n",
    "\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        out = out@v\n",
    "        return out\n",
    "\n",
    "h = Head(100)\n",
    "h(torch.rand(16, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T =10\n",
    "torch.tril(torch.ones(T, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
