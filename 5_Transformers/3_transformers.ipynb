{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "num_steps = 1000\n",
    "lr = 1e-3\n",
    "context_length = 32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8' ) as f:\n",
    "    data = f.read().lower()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '<UNK>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "chars.remove('3')\n",
    "chars.append('<UNK>')\n",
    "print(chars)\n",
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '$': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " ':': 9,\n",
       " ';': 10,\n",
       " '?': 11,\n",
       " 'a': 12,\n",
       " 'b': 13,\n",
       " 'c': 14,\n",
       " 'd': 15,\n",
       " 'e': 16,\n",
       " 'f': 17,\n",
       " 'g': 18,\n",
       " 'h': 19,\n",
       " 'i': 20,\n",
       " 'j': 21,\n",
       " 'k': 22,\n",
       " 'l': 23,\n",
       " 'm': 24,\n",
       " 'n': 25,\n",
       " 'o': 26,\n",
       " 'p': 27,\n",
       " 'q': 28,\n",
       " 'r': 29,\n",
       " 's': 30,\n",
       " 't': 31,\n",
       " 'u': 32,\n",
       " 'v': 33,\n",
       " 'w': 34,\n",
       " 'x': 35,\n",
       " 'y': 36,\n",
       " 'z': 37,\n",
       " '<UNK>': 38}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "for t in range(len(chars)):\n",
    "    vocab[t] = chars[t]\n",
    "\n",
    "rev_vocab = {v:k for k,v in vocab.items()}\n",
    "rev_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 16, 23, 23, 26, 38]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(text):\n",
    "    out = []\n",
    "    for t in text:\n",
    "        out.append(rev_vocab.get(t, 38)) # 38 is the <UNK>\n",
    "    return out\n",
    "\n",
    "\n",
    "encode('hello1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w-tr!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode(nums):\n",
    "    out = ''\n",
    "    for i in nums:\n",
    "        out += vocab.get(i, '<UNK>')\n",
    "    return out\n",
    "\n",
    "\n",
    "decode([34,  7, 31, 29, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003854, 111540)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = torch.tensor(encode(data), dtype=torch.long)\n",
    "train_data = encoded_data[:int(0.9*len(encoded_data))]\n",
    "test_data = encoded_data[int(0.9*len(encoded_data)):]\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[17, 20, 23, 23,  5, 15,  6,  1, 26, 32, 29,  1, 13, 23, 26, 26, 15,  1,\n",
       "          20, 30,  1, 14, 26, 23, 15,  6,  1, 12, 25, 15,  1, 31],\n",
       "         [19, 16,  1, 34, 16, 12, 29, 36,  1, 30, 32, 25,  1, 19, 12, 31, 19,  1,\n",
       "          24, 12, 15, 16,  1, 12,  1, 18, 26, 23, 15, 16, 25,  1],\n",
       "         [ 1, 20, 25,  1, 18, 29, 16, 16, 14, 16,  6,  7,  7,  0,  0, 24, 16, 25,\n",
       "          16, 25, 20, 32, 30,  9,  0, 34, 16, 23, 23,  6,  1, 34],\n",
       "         [26, 17,  1, 36, 26, 29, 22,  9,  0,  0, 19, 16, 25, 29, 36,  1, 13, 26,\n",
       "          23, 20, 25, 18, 13, 29, 26, 22, 16,  9,  0, 33, 20, 23],\n",
       "         [ 1, 17, 26, 29,  1, 31, 19, 16,  1, 30, 16, 23, 17, 30, 12, 24, 16,  1,\n",
       "          19, 16, 12, 33, 16, 25,  0, 31, 19, 12, 31,  1, 17, 29],\n",
       "         [ 6,  1, 12, 25, 15,  1, 15, 16, 12, 31, 19,  1, 31, 19, 36,  1, 23, 20,\n",
       "          17, 16,  2,  0,  0, 18, 23, 26, 32, 14, 16, 30, 31, 16],\n",
       "         [12, 25, 14, 16,  8,  0,  0, 22, 20, 25, 18,  1, 29, 20, 14, 19, 12, 29,\n",
       "          15,  1, 20, 20,  9,  0, 25, 26, 29, 31, 19, 32, 24, 13],\n",
       "         [12,  1, 19, 12, 27, 27, 36,  1, 31, 19, 20, 25, 18,  0, 31, 26,  1, 13,\n",
       "          16,  1, 31, 19, 16,  1, 17, 12, 31, 19, 16, 29,  1, 32],\n",
       "         [19, 16,  1, 17, 26, 29, 24,  1, 26, 17,  1, 23, 12, 34,  6,  0, 27, 29,\n",
       "          26, 14, 16, 16, 15,  1, 31, 19, 32, 30,  1, 29, 12, 30],\n",
       "         [31, 19,  1, 25, 16, 18, 23, 16, 14, 31,  1, 25, 26,  1, 18, 29, 16, 12,\n",
       "          31,  1, 15, 16, 30, 20, 18, 25, 30,  6,  0, 34, 19, 20],\n",
       "         [ 1, 34, 20, 23, 23,  1, 13, 29, 20, 25, 18,  1, 36, 26, 32,  1, 24, 12,\n",
       "          25, 36,  1, 17, 29, 20, 16, 25, 15, 30,  8,  0,  0, 22],\n",
       "         [29, 26, 30, 30,  9,  0, 19, 16,  1, 19, 12, 31, 19,  1, 25, 26, 31,  1,\n",
       "          24, 26, 25, 16, 36,  1, 17, 26, 29,  1, 31, 19, 16, 30],\n",
       "         [16,  1, 27, 29, 20, 15, 16,  0, 31, 26,  1, 15, 26,  1, 24, 36, 30, 16,\n",
       "          23, 17,  1, 31, 19, 20, 30,  1, 34, 29, 26, 25, 18,  9],\n",
       "         [31, 11,  1, 27, 29, 26, 14, 16, 16, 15,  6,  1, 14, 26, 24, 20, 25, 20,\n",
       "          32, 30,  8,  0,  0, 14, 26, 24, 20, 25, 20, 32, 30,  9],\n",
       "         [ 1, 19, 20, 30,  8,  0,  0, 21, 32, 23, 20, 16, 31,  9,  0, 20,  1, 15,\n",
       "          26,  1, 14, 26, 25, 17, 16, 30, 30,  1, 20, 31,  6,  1],\n",
       "         [ 6,  1, 31, 19, 26, 32,  1, 12, 29, 31,  1, 15, 12, 24, 25,  5, 15,  1,\n",
       "          31, 26,  1, 19, 16, 23, 23,  1, 17, 26, 29,  1, 31, 19]],\n",
       "        device='cuda:0'),\n",
       " tensor([[20, 23, 23,  5, 15,  6,  1, 26, 32, 29,  1, 13, 23, 26, 26, 15,  1, 20,\n",
       "          30,  1, 14, 26, 23, 15,  6,  1, 12, 25, 15,  1, 31, 19],\n",
       "         [16,  1, 34, 16, 12, 29, 36,  1, 30, 32, 25,  1, 19, 12, 31, 19,  1, 24,\n",
       "          12, 15, 16,  1, 12,  1, 18, 26, 23, 15, 16, 25,  1, 30],\n",
       "         [20, 25,  1, 18, 29, 16, 16, 14, 16,  6,  7,  7,  0,  0, 24, 16, 25, 16,\n",
       "          25, 20, 32, 30,  9,  0, 34, 16, 23, 23,  6,  1, 34, 16],\n",
       "         [17,  1, 36, 26, 29, 22,  9,  0,  0, 19, 16, 25, 29, 36,  1, 13, 26, 23,\n",
       "          20, 25, 18, 13, 29, 26, 22, 16,  9,  0, 33, 20, 23, 23],\n",
       "         [17, 26, 29,  1, 31, 19, 16,  1, 30, 16, 23, 17, 30, 12, 24, 16,  1, 19,\n",
       "          16, 12, 33, 16, 25,  0, 31, 19, 12, 31,  1, 17, 29, 26],\n",
       "         [ 1, 12, 25, 15,  1, 15, 16, 12, 31, 19,  1, 31, 19, 36,  1, 23, 20, 17,\n",
       "          16,  2,  0,  0, 18, 23, 26, 32, 14, 16, 30, 31, 16, 29],\n",
       "         [25, 14, 16,  8,  0,  0, 22, 20, 25, 18,  1, 29, 20, 14, 19, 12, 29, 15,\n",
       "           1, 20, 20,  9,  0, 25, 26, 29, 31, 19, 32, 24, 13, 16],\n",
       "         [ 1, 19, 12, 27, 27, 36,  1, 31, 19, 20, 25, 18,  0, 31, 26,  1, 13, 16,\n",
       "           1, 31, 19, 16,  1, 17, 12, 31, 19, 16, 29,  1, 32, 25],\n",
       "         [16,  1, 17, 26, 29, 24,  1, 26, 17,  1, 23, 12, 34,  6,  0, 27, 29, 26,\n",
       "          14, 16, 16, 15,  1, 31, 19, 32, 30,  1, 29, 12, 30, 19],\n",
       "         [19,  1, 25, 16, 18, 23, 16, 14, 31,  1, 25, 26,  1, 18, 29, 16, 12, 31,\n",
       "           1, 15, 16, 30, 20, 18, 25, 30,  6,  0, 34, 19, 20, 14],\n",
       "         [34, 20, 23, 23,  1, 13, 29, 20, 25, 18,  1, 36, 26, 32,  1, 24, 12, 25,\n",
       "          36,  1, 17, 29, 20, 16, 25, 15, 30,  8,  0,  0, 22, 20],\n",
       "         [26, 30, 30,  9,  0, 19, 16,  1, 19, 12, 31, 19,  1, 25, 26, 31,  1, 24,\n",
       "          26, 25, 16, 36,  1, 17, 26, 29,  1, 31, 19, 16, 30, 16],\n",
       "         [ 1, 27, 29, 20, 15, 16,  0, 31, 26,  1, 15, 26,  1, 24, 36, 30, 16, 23,\n",
       "          17,  1, 31, 19, 20, 30,  1, 34, 29, 26, 25, 18,  9,  1],\n",
       "         [11,  1, 27, 29, 26, 14, 16, 16, 15,  6,  1, 14, 26, 24, 20, 25, 20, 32,\n",
       "          30,  8,  0,  0, 14, 26, 24, 20, 25, 20, 32, 30,  9,  0],\n",
       "         [19, 20, 30,  8,  0,  0, 21, 32, 23, 20, 16, 31,  9,  0, 20,  1, 15, 26,\n",
       "           1, 14, 26, 25, 17, 16, 30, 30,  1, 20, 31,  6,  1, 12],\n",
       "         [ 1, 31, 19, 26, 32,  1, 12, 29, 31,  1, 15, 12, 24, 25,  5, 15,  1, 31,\n",
       "          26,  1, 19, 16, 23, 23,  1, 17, 26, 29,  1, 31, 19, 20]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_batch(split='train'):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    start = torch.randint(0,len(data)-context_length-1,(batch_size,))\n",
    "    outx = torch.stack([data[i:i+context_length] for i in start]).to(device)\n",
    "    if split == 'test': return outx\n",
    "    outy = torch.stack([data[i+1:i+context_length+1] for i in start]).to(device)\n",
    "    if split == 'train': return outx, outy\n",
    "\n",
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
